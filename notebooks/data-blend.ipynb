{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from src import common, string_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffortune = pd.read_csv('../data/fortune/f500_full_firm_data.csv')\n",
    "dfsample = pd.read_csv('../data/fortune/f500_final_firm_sample.csv')\n",
    "dffortune_sample = dffortune.loc[lambda x: ((x['ranking']<=300)\n",
    "                                          & (x['include']==True))\n",
    "                                          | (x['firmhash'].isin(dfsample['firmhash']))].drop(columns=['include', 'ranklabel']).reset_index(drop=True)\n",
    "\n",
    "manual_scores_2019 = {\n",
    "    'Adobe': 7.86,\n",
    "    'HCA Healthcare': 6.89,\n",
    "    'Prudential Financial (U.S.)': 6.47,\n",
    "    'Loweâ€™s': 5.76\n",
    "}\n",
    "\n",
    "for k, v in manual_scores_2019.items():\n",
    "    dffortune_sample.loc[lambda x: x['firm']==k, 'reputation_score_2019'] = v\n",
    "\n",
    "dffortune_sample_r_growth = dffortune_sample.loc[lambda x: (~x['reputation_score_2020'].isnull()) & (~x['reputation_score_2019'].isnull())][['reputation_score_2020', 'reputation_score_2019']]\n",
    "dffortune_sample_r_growth = dffortune_sample_r_growth.loc[lambda x: (x['reputation_score_2020']!='-') & (x['reputation_score_2019']!='-')]\n",
    "\n",
    "dffortune_sample_r_growth = dffortune_sample_r_growth.astype(float).round(5)\n",
    "dffortune_sample_r_growth['reputation_score_growth'] = (dffortune_sample_r_growth['reputation_score_2020'] - dffortune_sample_r_growth['reputation_score_2019']) / dffortune_sample_r_growth['reputation_score_2019']\n",
    "\n",
    "dffortune_sample = pd.concat([dffortune_sample, dffortune_sample_r_growth[['reputation_score_growth']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-cleaning",
   "metadata": {},
   "source": [
    "### privacy policy features (alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp_features = pd.read_csv('../data/policies/features/firm_pp_features_0.3.0.csv')\n",
    "df_pp_features = df_pp_features.drop(columns=['firm'])\n",
    "df_pp_features.columns = [f'pp_{c}' if c != 'firmhash' else c for c in df_pp_features.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-tribune",
   "metadata": {},
   "source": [
    "### n data breaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prc_data_breaches = pd.read_csv('../data/breaches/prc_firm_data_breach_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-region",
   "metadata": {},
   "source": [
    "### controls 1 ==> age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_1 = pd.read_csv('../data/dbs/date_of_incorporation_and_stock_turnover.csv')\n",
    "df_control_add = pd.read_csv('../data/dbs/date_of_incorporation_and_stock_turnover_additional.csv')\n",
    "df_control_add['stock_turnover'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_control_1(dataf):\n",
    "\n",
    "    dataf['stock_turnover'] = dataf['stock_turnover'].str.replace(',', '.')\n",
    "    dataf['stock_turnover'] = dataf['stock_turnover'].replace('n.a.', None)\n",
    "    dataf['stock_turnover'] = dataf['stock_turnover'].replace('n.s.', None)\n",
    "    dataf['stock_turnover'] = dataf['stock_turnover'].astype(float)\n",
    "\n",
    "    dataf = common.column_to_date(dataf, 'date_of_incorporation')\n",
    "    dataf = dataf.rename(columns={'last_available_year': 'stock_turnover_last_available_year'})\n",
    "\n",
    "    dataf['age_in_years'] = round((pd.Timestamp.now() - pd.to_datetime(dataf['date_of_incorporation'])).dt.days / 364.24, 1)\n",
    "    \n",
    "    return dataf\n",
    "\n",
    "df_control_1 = pd.read_csv('../data/dbs/date_of_incorporation_and_stock_turnover.csv')\n",
    "df_control_1_add = pd.read_csv('../data/dbs/date_of_incorporation_and_stock_turnover_additional.csv')\n",
    "df_control_1_add['stock_turnover'] = None\n",
    "    \n",
    "df_control_1 = prep_control_1(df_control_1)\n",
    "df_control_1_add = prep_control_1(df_control_1_add)\n",
    "df_control_1 = pd.concat([df_control_1, df_control_1_add])\n",
    "\n",
    "df_control_1, _, __ = string_matching.match_firm_hash(dffortune_sample, df_control_1)\n",
    "print(f'n no match: {_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-hungary",
   "metadata": {},
   "source": [
    "### control 2 ==> roa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_control_2(dataf):\n",
    "    dataf = dataf[['firm', 'return_on_assets']].copy()\n",
    "    try:\n",
    "        dataf['return_on_assets'] = dataf['return_on_assets'].str.replace(',', '.').astype(float)\n",
    "    except:\n",
    "        pass\n",
    "    return dataf\n",
    "\n",
    "df_contron_2 = pd.read_csv('../data/dbs/return_on_assets.csv')\n",
    "df_control_2_add = pd.read_csv('../data/dbs/return_on_assets_additional.csv')\n",
    "\n",
    "df_contron_2 = prep_control_2(df_contron_2)\n",
    "df_control_2_add = prep_control_2(df_control_2_add)\n",
    "\n",
    "df_contron_2 = pd.concat([df_contron_2, df_control_2_add])\n",
    "\n",
    "df_contron_2, _, __ = string_matching.match_firm_hash(dffortune_sample, df_contron_2)\n",
    "print(f'n no match: {_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-slide",
   "metadata": {},
   "source": [
    "### controls 3 ==> csr score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csr_index = pd.read_csv('../data/msci_kld/msci_kld_social_ratings.csv')\n",
    "df_csr_index = df_csr_index.rename(columns={'last_available_year': 'csr_index_last_available_year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-process",
   "metadata": {},
   "source": [
    "### employee ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee = pd.read_csv('../data/dbs/employee_satisfaction_glassdoor.csv')\n",
    "df_employee = df_employee.drop(columns=['Industry', 'Sector'])\n",
    "df_employee.columns = [common.to_clean_string(c) for c in df_employee.columns]\n",
    "df_employee, _, __ = string_matching.match_firm_hash(dffortune_sample, df_employee)\n",
    "print(f'n no match: {_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-contractor",
   "metadata": {},
   "source": [
    "### privacy policy features (manuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ig_manuals(dataf):\n",
    "    dataf.columns = [c.strip() for c in dataf.columns]\n",
    "    dataf['privacy_policy_url'] = dataf['Privacy Policy URL corrected']\n",
    "    dataf['privacy_policy_url'] = dataf['privacy_policy_url'].fillna(dataf['Privacy Policy URL'])\n",
    "    dataf = dataf.drop(columns=['Industry', 'Sector', 'Collector', 'Comment', 'Privacy Policy URL', 'Privacy Policy URL corrected'])\n",
    "    dataf.columns = [common.to_clean_string(c) for c in dataf.columns]\n",
    "    return dataf\n",
    "\n",
    "df_ig_manuals = pd.read_csv('../data/dbs/information_governance_practises_manuals.csv')\n",
    "df_ig_manuals_additional = pd.read_csv('../data/dbs/information_governance_practises_manuals_additional.csv')\n",
    "\n",
    "df_ig_manuals = prep_ig_manuals(df_ig_manuals)\n",
    "df_ig_manuals_additional = prep_ig_manuals(df_ig_manuals_additional)\n",
    "df_ig_manuals = pd.concat([df_ig_manuals, df_ig_manuals_additional])\n",
    "\n",
    "df_ig_manuals, _, __ = string_matching.match_firm_hash(dffortune_sample, df_ig_manuals)\n",
    "df_ig_manuals.columns = [f'pp_{c}' if c != 'firmhash' else c for c in df_ig_manuals.columns]\n",
    "print(f'n no match: {_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-choice",
   "metadata": {},
   "source": [
    "### iss proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iss_share_pros = pd.read_csv('../data/dbs/iss_shareholder_proposals.csv')\n",
    "df_iss_share_pros.columns = [common.to_clean_string(c) for c in df_iss_share_pros.columns]\n",
    "df_iss_share_pros = common.column_to_date(df_iss_share_pros, 'meeting_date')\n",
    "df_iss_share_pros = df_iss_share_pros.rename(columns={'company_name': 'firm'})\n",
    "\n",
    "df_iss_share_pros_count = df_iss_share_pros.groupby('firm', as_index=False)[['other_status']].count().rename(columns={'other_status': 'number_of_shareholder_proposals'})\n",
    "\n",
    "df_iss_share_pros_count, _, __ = string_matching.match_firm_hash(dffortune_sample, df_iss_share_pros_count)\n",
    "print(f'n no match: {_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-underground",
   "metadata": {},
   "source": [
    "### long-short term investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investors_shortlong = pd.read_csv('../data/dbs/long_short_term_investments.csv')\n",
    "df_investors_shortlong.columns = [common.to_clean_string(c) for c in df_investors_shortlong.columns]\n",
    "df_investors_shortlong.loc[lambda x: x['longterm']==0, 'share_shortterm_investors'] = df_investors_shortlong['share_percent']\n",
    "df_investors_shortlong.loc[lambda x: x['longterm']==1, 'share_longterm_investors'] = df_investors_shortlong['share_percent']\n",
    "df_shortlong_summed = df_investors_shortlong.groupby('firm', as_index=False)[['share_shortterm_investors', 'share_longterm_investors']].sum()\n",
    "df_shortlong_summed, _, __ = string_matching.match_firm_hash(dffortune_sample, df_shortlong_summed)\n",
    "print(f'n no match: {_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blended = dffortune_sample \\\n",
    ".merge(df_control_1, how='left', on='firmhash') \\\n",
    ".merge(df_contron_2, how='left', on='firmhash') \\\n",
    ".merge(df_pp_features, how='left', on='firmhash') \\\n",
    ".merge(df_ig_manuals, how='left', on='firmhash') \\\n",
    ".merge(df_prc_data_breaches, how='left', on='firmhash') \\\n",
    ".merge(df_csr_index, how='left', on='firmhash') \\\n",
    ".merge(df_employee, how='left', on='firmhash') \\\n",
    ".merge(df_iss_share_pros_count, how='left', on='firmhash') \\\n",
    ".merge(df_shortlong_summed, how='left', on='firmhash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blended.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-leadership",
   "metadata": {},
   "source": [
    "### checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blended['pp_legislation_complied_with'] = df_blended['pp_legislation_complied_with'].str.strip().str.lower()\n",
    "for c in ['stock_turnover_last_available_year', 'csr_index_last_available_year']:\n",
    "    df_blended[c] = df_blended[c].fillna(-99).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-messenger",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blended.to_csv('../data/modelinput/information_governance_full_dataset.csv',\n",
    "                  index=False,\n",
    "                  quoting=csv.QUOTE_NONNUMERIC,\n",
    "                  quotechar='\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
