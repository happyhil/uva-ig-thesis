{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-swedish",
   "metadata": {},
   "source": [
    "## import company data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"https://fortune.com/company/liberty-oilfield-services/fortune500/\")\n",
    "count = 0\n",
    "fulldict = {}\n",
    "while count < 1200:\n",
    "    if count > 0:\n",
    "        try:\n",
    "            button = driver.find_element_by_class_name('companySinglePagination__prev--3QWI8')\n",
    "            button.click()\n",
    "        except:\n",
    "            break\n",
    "    try:\n",
    "        cdict = {}\n",
    "        cdict['Company Tag'] = driver.current_url.split('/')[-3]\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        companysoup = soup.find(\"div\", {\"class\": \"info__wrapper--1CxpW\"})\n",
    "        for d in companysoup.find_all('div'):\n",
    "            if len(d) > 1:\n",
    "                dsplit = d.find_all('div')\n",
    "                asplit = d.find_all('a')\n",
    "                if len(dsplit) == 2:\n",
    "                    cdict[dsplit[0].text] = dsplit[1].text\n",
    "                elif len(asplit) == 1:\n",
    "                    cdict[dsplit[0].text] = asplit[0].text\n",
    "                else:\n",
    "                    pass\n",
    "        rank = int(soup.find(\"div\", {\"class\": \"companyTitle__rank--2SYbW\"}).text.split('K')[-1].replace(' ', ''))\n",
    "        cdict['Rank'] = rank\n",
    "        companyname = soup.find(\"h1\", {\"class\": \"companyTitle__title--3Bdrv\"}).find('a').find('div')\n",
    "        fulldict[companyname.text] = cdict\n",
    "    except:\n",
    "        pass\n",
    "    count += 1\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/f500_ranking_2020.json', 'w') as outfile:\n",
    "    json.dump(fulldict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-error",
   "metadata": {},
   "source": [
    "## import company sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"https://fortune.com/fortune500/2020/search/\")\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "sectorsoup = soup.find('select', {'class': 'input__inputElement--1OLBW'})\n",
    "\n",
    "sectors = []\n",
    "for s in sectorsoup.find_all('option'):\n",
    "    if s.text != '':\n",
    "        sectors.append(s.text)\n",
    "\n",
    "urlbuildups = {\n",
    "    ',': '%2C',\n",
    "    ' ': '%20',\n",
    "    '&': '%26'\n",
    "}\n",
    "\n",
    "baseurl = 'https://fortune.com/fortune500/2020/search/?sector={}'\n",
    "fulldict = {}\n",
    "for e in sectors:\n",
    "    e_clean = e\n",
    "    for k, v in urlbuildups.items():\n",
    "        e = e.replace(k, v)\n",
    "    formattedurl = baseurl.format(e)\n",
    "    \n",
    "    driver.get(formattedurl)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    dropdown = driver.find_element_by_class_name('select-wrap')\n",
    "    options = dropdown.find_elements_by_tag_name(\"option\")\n",
    "    options[-1].click()\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    subdict = {}\n",
    "    for c in soup.find_all('div', {\"class\": \"rt-tr-group\"}):\n",
    "        company = c.find_all('div')\n",
    "        subdict[company[0].find_all('div')[1].text] = company[0].find_all('div')[2].text\n",
    "    fulldict[e_clean] = subdict\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/f500_company_sectors.json', 'w') as outfile:\n",
    "    json.dump(fulldict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
