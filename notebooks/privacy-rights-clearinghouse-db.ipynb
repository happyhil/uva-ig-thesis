{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from src import common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-seminar",
   "metadata": {},
   "source": [
    "source of similarity matcher: https://stackoverflow.com/questions/6400416/figure-out-if-a-business-name-is-very-similar-to-another-one-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_clean_tokens(firmname):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    decrease = 1\n",
    "    while decrease > 0:\n",
    "        start_len = len(firmname)\n",
    "        firmname = firmname.replace('  ', ' ')\n",
    "        decrease = start_len - len(firmname)\n",
    "    tokens = firmname.split()\n",
    "    tokens_cleans = [re.sub(\"[^0-9a-zA-Z]+\", \"\", t).lower() for t in tokens]\n",
    "    tokens_cleans = [t for t in tokens_cleans if t not in stopwords.words('english')]\n",
    "    tokens_filtered = [t for t in tokens_cleans if len(t) > 0]\n",
    "    \n",
    "    return tokens_filtered\n",
    "\n",
    "\n",
    "def sequence_uniqueness(tokens, token_frequency_dict):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    return sum(1 / token_frequency_dict[t] ** 0.5 for t in tokens)\n",
    "\n",
    "\n",
    "def name_similarity(name_a, name_b, token_frequency):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    a_tokens = set(name_a)\n",
    "    b_tokens = set(name_b)\n",
    "    a_uniq = sequence_uniqueness(name_a, token_frequency)\n",
    "    b_uniq = sequence_uniqueness(name_b, token_frequency)\n",
    "    if a_uniq == 0 or b_uniq == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sequence_uniqueness(a_tokens.intersection(b_tokens), token_frequency) / (a_uniq * b_uniq) ** 0.5\n",
    "\n",
    "    \n",
    "def build_token_frequency_table(token_lists):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    tokens = [str(token) for s in token_lists for token in s]\n",
    "    return Counter(tokens)\n",
    "\n",
    "\n",
    "def count_prc_existence(df_fortune, df_prc):\n",
    "    \n",
    "    fortune_companies = list(df_fortune['firm'].values)\n",
    "    prc_companies = list(df_prc['Company'].values)\n",
    "\n",
    "    fortune_companies_tokenized = [to_clean_tokens(f) for f in fortune_companies]\n",
    "    prc_companies_tokenized = [to_clean_tokens(f) for f in prc_companies]\n",
    "    all_companies_tokenized = [*prc_companies_tokenized, *fortune_companies_tokenized]\n",
    "    \n",
    "    token_frequency = build_token_frequency_table(all_companies_tokenized)\n",
    "    \n",
    "    prc_existance = {}\n",
    "    for firmname, firmtokens in zip(fortune_companies, fortune_companies_tokenized):\n",
    "        prc_existance[common.__hash(firmname)] = 0\n",
    "        for matchtokens in prc_companies_tokenized:\n",
    "            matchscore = name_similarity(firmtokens, matchtokens, token_frequency)\n",
    "            if matchscore >= 0.7:\n",
    "                prc_existance[common.__hash(firmname)] += 1\n",
    "                \n",
    "    return prc_existance, token_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prc = pd.read_csv('../data/dbs/prc_data_breach_chronology.1.13.20.csv')\n",
    "df_fortune = pd.read_csv('../data/fortune/f500_firm_sample.csv')\n",
    "\n",
    "df_prc['Date Made Public'] = pd.to_datetime(df_prc['Date Made Public'], format='%m/%d/%Y')\n",
    "df_prc_filtered = df_prc.loc[lambda x: x['Date Made Public']>='2010-01-01']\n",
    "\n",
    "firm_data_breaches, _ = count_prc_existence(df_fortune, df_prc_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_firm_data_breaches = pd.DataFrame({\n",
    "    'firmhash': firm_data_breaches.keys(),\n",
    "    'n_data_breaches': firm_data_breaches.values()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/breaches/prc_firm_data_breach_matches.json', 'w') as outstream:\n",
    "    json.dump(firm_data_breaches, outstream)\n",
    "df_firm_data_breaches.to_csv('../data/breaches/prc_firm_data_breach_matches.csv',\n",
    "                             index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-germany",
   "metadata": {},
   "source": [
    "### - devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_similarity(['apple', 'inc', 'union', 'llc'], ['apple'], _)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
